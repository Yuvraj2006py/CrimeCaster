name: Quarterly Data Pipeline

on:
  schedule:
    # Runs on 1st day of Jan, Apr, Jul, Oct at 2:00 AM UTC
    # Cron format: minute hour day month day-of-week
    # This equals: 9:00 PM EST / 10:00 PM EDT (previous day)
    - cron: '0 2 1 1,4,7,10 *'
  workflow_dispatch:  # Allows manual trigger from GitHub UI

env:
  PYTHON_VERSION: '3.11'
  PIP_CACHE_DIR: ~/.cache/pip

jobs:
  run-pipeline:
    name: Run Quarterly Data Pipeline
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Pipeline should complete within 60 minutes
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            gcc \
            g++ \
            libpq-dev \
            libgdal-dev \
            gdal-bin \
            libgeos-dev \
            libproj-dev \
            curl
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e .
      
      - name: Create logs directory
        run: mkdir -p logs
      
      - name: Run Bronze Layer
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -m ingestion.bronze.csv_loader --all-datasets --max-workers 5
        continue-on-error: false
      
      - name: Run Silver Layer
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -m ingestion.silver.cleaner
        continue-on-error: false
      
      - name: Run Gold Layer
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -m transformations.gold.h3_mapper
        continue-on-error: false
      
      - name: Upload logs
        if: always()  # Upload logs even if pipeline fails
        uses: actions/upload-artifact@v3
        with:
          name: pipeline-logs-${{ github.run_id }}
          path: logs/
          retention-days: 30
      
      - name: Pipeline Summary
        if: always()
        run: |
          echo "## Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Pipeline completed at $(date)" >> $GITHUB_STEP_SUMMARY
          echo "Check logs artifact for detailed information" >> $GITHUB_STEP_SUMMARY
          if [ -f logs/pipeline_*.log ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Last 20 lines of log:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -n 20 logs/pipeline_*.log >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

